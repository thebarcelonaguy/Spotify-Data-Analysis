{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import ipywidgets as widgets # interactive widgets\n",
    "from ipywidgets import Box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>469281.000000</td>\n",
       "      <td>4.692810e+05</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.578334</td>\n",
       "      <td>2.299850e+05</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>0.563647</td>\n",
       "      <td>0.542439</td>\n",
       "      <td>5.224840</td>\n",
       "      <td>-10.200712</td>\n",
       "      <td>0.659208</td>\n",
       "      <td>0.104881</td>\n",
       "      <td>0.449396</td>\n",
       "      <td>0.113413</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.552442</td>\n",
       "      <td>118.465459</td>\n",
       "      <td>3.873500</td>\n",
       "      <td>1.295914</td>\n",
       "      <td>1988.594946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.366320</td>\n",
       "      <td>1.270919e+05</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.166195</td>\n",
       "      <td>0.251780</td>\n",
       "      <td>3.517928</td>\n",
       "      <td>5.086349</td>\n",
       "      <td>0.473976</td>\n",
       "      <td>0.179904</td>\n",
       "      <td>0.348656</td>\n",
       "      <td>0.266952</td>\n",
       "      <td>0.184386</td>\n",
       "      <td>0.257641</td>\n",
       "      <td>29.784032</td>\n",
       "      <td>0.472858</td>\n",
       "      <td>0.887235</td>\n",
       "      <td>22.813764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.344000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.750530e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-12.887000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>95.549000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.149070e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-9.233000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>117.363000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.638000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-6.482000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>136.335000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>5.621218e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.376000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>243.507000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          popularity   duration_ms       explicit   danceability  \\\n",
       "count  469281.000000  4.692810e+05  469281.000000  469281.000000   \n",
       "mean       27.578334  2.299850e+05       0.044155       0.563647   \n",
       "std        18.366320  1.270919e+05       0.205439       0.166195   \n",
       "min         0.000000  3.344000e+03       0.000000       0.000000   \n",
       "25%        13.000000  1.750530e+05       0.000000       0.453000   \n",
       "50%        27.000000  2.149070e+05       0.000000       0.577000   \n",
       "75%        41.000000  2.638000e+05       0.000000       0.686000   \n",
       "max        98.000000  5.621218e+06       1.000000       0.991000   \n",
       "\n",
       "              energy            key       loudness           mode  \\\n",
       "count  469281.000000  469281.000000  469281.000000  469281.000000   \n",
       "mean        0.542439       5.224840     -10.200712       0.659208   \n",
       "std         0.251780       3.517928       5.086349       0.473976   \n",
       "min         0.000000       0.000000     -60.000000       0.000000   \n",
       "25%         0.344000       2.000000     -12.887000       0.000000   \n",
       "50%         0.550000       5.000000      -9.233000       1.000000   \n",
       "75%         0.749000       8.000000      -6.482000       1.000000   \n",
       "max         1.000000      11.000000       5.376000       1.000000   \n",
       "\n",
       "         speechiness   acousticness  instrumentalness       liveness  \\\n",
       "count  469281.000000  469281.000000     469281.000000  469281.000000   \n",
       "mean        0.104881       0.449396          0.113413       0.213992   \n",
       "std         0.179904       0.348656          0.266952       0.184386   \n",
       "min         0.000000       0.000000          0.000000       0.000000   \n",
       "25%         0.034000       0.096900          0.000000       0.098300   \n",
       "50%         0.044300       0.422000          0.000024       0.139000   \n",
       "75%         0.076400       0.784000          0.009460       0.278000   \n",
       "max         0.971000       0.996000          1.000000       1.000000   \n",
       "\n",
       "             valence          tempo  time_signature    num_artists  \\\n",
       "count  469281.000000  469281.000000   469281.000000  469281.000000   \n",
       "mean        0.552442     118.465459        3.873500       1.295914   \n",
       "std         0.257641      29.784032        0.472858       0.887235   \n",
       "min         0.000000       0.000000        0.000000       1.000000   \n",
       "25%         0.346000      95.549000        4.000000       1.000000   \n",
       "50%         0.564000     117.363000        4.000000       1.000000   \n",
       "75%         0.769000     136.335000        4.000000       1.000000   \n",
       "max         1.000000     243.507000        5.000000      58.000000   \n",
       "\n",
       "                year  \n",
       "count  469281.000000  \n",
       "mean     1988.594946  \n",
       "std        22.813764  \n",
       "min      1922.000000  \n",
       "25%      1974.000000  \n",
       "50%      1992.000000  \n",
       "75%      2007.000000  \n",
       "max      2021.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/tracks_cleaned.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Key is already an estimated value instead of actual we will drop it from the frame. Additonally, we drop release_date due to the inconsisitencies in the data where release_months are only available for some of the data. Since we have already created a column called year in the data cleaning part, we are still able to use that and take advantage of the strong relation between year and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['key', 'release_date'],axis=1, inplace=True)\n",
    "\n",
    "time_signature_df=pd.get_dummies(df[\"time_signature\"])\n",
    "df = pd.concat([df,time_signature_df],axis=1)\n",
    "df['mode'] = np.where(df['mode']=='Major', 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Modeling the data + Sets Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"] # all the features except popularity\n",
    "y = df[\"popularity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 469281 entries, 0 to 469280\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   duration_ms       469281 non-null  int64  \n",
      " 1   explicit          469281 non-null  int64  \n",
      " 2   danceability      469281 non-null  float64\n",
      " 3   energy            469281 non-null  float64\n",
      " 4   loudness          469281 non-null  float64\n",
      " 5   mode              469281 non-null  int64  \n",
      " 6   speechiness       469281 non-null  float64\n",
      " 7   acousticness      469281 non-null  float64\n",
      " 8   instrumentalness  469281 non-null  float64\n",
      " 9   liveness          469281 non-null  float64\n",
      " 10  valence           469281 non-null  float64\n",
      " 11  tempo             469281 non-null  float64\n",
      " 12  time_signature    469281 non-null  int64  \n",
      " 13  num_artists       469281 non-null  int64  \n",
      " 14  year              469281 non-null  int64  \n",
      " 15  0                 469281 non-null  uint8  \n",
      " 16  1                 469281 non-null  uint8  \n",
      " 17  3                 469281 non-null  uint8  \n",
      " 18  4                 469281 non-null  uint8  \n",
      " 19  5                 469281 non-null  uint8  \n",
      "dtypes: float64(9), int64(6), uint8(5)\n",
      "memory usage: 55.9 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_decision_tree' (DecisionTreeRegressor)\n",
      "Average Train Accuracy = 0.9950156144813767\n",
      "Average Test Accuracy = 0.02713350038355622\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1):\n",
    "    # separate the data to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # save as np.array\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train) \n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #creating a regression model\n",
    "    model_decision_tree = DecisionTreeRegressor()\n",
    "    model_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    %store model_decision_tree\n",
    "\n",
    "    #We estimate models’ success rate in predicting the songs using the score() function which calculates the coefficient of determination. A score which is closer to 1 means the regressor is more accurate.\n",
    "    train = model_decision_tree.score(X_train, y_train)\n",
    "    test = model_decision_tree.score(X_test, y_test)\n",
    "\n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train = sum(train_scores) / len(train_scores)\n",
    "avg_test = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(\"Average Train Accuracy = \" + str(avg_train))\n",
    "print(\"Average Test Accuracy = \" + str(avg_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, when non-neglgible factors are accounted for, the success rate of a decision-tree model in predicting popularity in test set is 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Non-essential factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/tracks_cleaned.csv')\n",
    "df.describe()\n",
    "\n",
    "df.drop(['key', 'release_date', 'num_artists', 'mode', 'speechiness', 'liveness', 'valence', 'tempo', 'time_signature'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"] # all the features except popularity\n",
    "y = df[\"popularity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Accuracy = 0.9948128314723499\n",
      "Average Test Accuracy = 0.00587793496739597\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1):\n",
    "    # separate the data to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # save as np.array\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train) \n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #creating a regression model\n",
    "    model_decision_tree = DecisionTreeRegressor()\n",
    "    model_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #We estimate models’ success rate in predicting the songs using the score() function which calculates the coefficient of determination. A score which is closer to 1 means the regressor is more accurate.\n",
    "    train = model_decision_tree.score(X_train, y_train)\n",
    "    test = model_decision_tree.score(X_test, y_test)\n",
    "\n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train = sum(train_scores) / len(train_scores)\n",
    "avg_test = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(\"Average Train Accuracy = \" + str(avg_train))\n",
    "print(\"Average Test Accuracy = \" + str(avg_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, dropping the non-essential features reduces the accuracy by around 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using top 6 features from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/tracks_cleaned.csv')\n",
    "df.describe()\n",
    "\n",
    "df.drop(['key', 'release_date', 'num_artists', 'mode', 'speechiness', 'liveness', 'valence', 'tempo', 'time_signature', 'instrumentalness'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"] # all the features except popularity\n",
    "y = df[\"popularity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Accuracy = 0.9945074035424195\n",
      "Average Test Accuracy = -0.015102234350520938\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(1):\n",
    "    # separate the data to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # save as np.array\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train) \n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #creating a regression model\n",
    "    model_decision_tree = DecisionTreeRegressor()\n",
    "    model_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    #We estimate models’ success rate in predicting the songs using the score() function which calculates the coefficient of determination. A score which is closer to 1 means the regressor is more accurate.\n",
    "    train = model_decision_tree.score(X_train, y_train)\n",
    "    test = model_decision_tree.score(X_test, y_test)\n",
    "\n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train = sum(train_scores) / len(train_scores)\n",
    "avg_test = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(\"Average Train Accuracy = \" + str(avg_train))\n",
    "print(\"Average Test Accuracy = \" + str(avg_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the number of features further to important features reduces the success score of the decision-tree model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, when it comes to decision-tree models, using such a model for prediciton gives really poor scores.\n",
    "\n",
    "Additionally, addressing the decision tree model, the negative score implies that this model’s performance is worse than just guessing the expected value no matter what song is being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
