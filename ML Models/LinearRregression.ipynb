{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import ipywidgets as widgets # interactive widgets\n",
    "from ipywidgets import Box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>469281.000000</td>\n",
       "      <td>4.692810e+05</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "      <td>469281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.578334</td>\n",
       "      <td>2.299850e+05</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>0.563647</td>\n",
       "      <td>0.542439</td>\n",
       "      <td>5.224840</td>\n",
       "      <td>-10.200712</td>\n",
       "      <td>0.659208</td>\n",
       "      <td>0.104881</td>\n",
       "      <td>0.449396</td>\n",
       "      <td>0.113413</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.552442</td>\n",
       "      <td>118.465459</td>\n",
       "      <td>3.873500</td>\n",
       "      <td>1.295914</td>\n",
       "      <td>1988.594946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.366320</td>\n",
       "      <td>1.270919e+05</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.166195</td>\n",
       "      <td>0.251780</td>\n",
       "      <td>3.517928</td>\n",
       "      <td>5.086349</td>\n",
       "      <td>0.473976</td>\n",
       "      <td>0.179904</td>\n",
       "      <td>0.348656</td>\n",
       "      <td>0.266952</td>\n",
       "      <td>0.184386</td>\n",
       "      <td>0.257641</td>\n",
       "      <td>29.784032</td>\n",
       "      <td>0.472858</td>\n",
       "      <td>0.887235</td>\n",
       "      <td>22.813764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.344000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.750530e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-12.887000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>95.549000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.149070e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-9.233000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>117.363000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.638000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-6.482000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>136.335000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>5.621218e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.376000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>243.507000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          popularity   duration_ms       explicit   danceability  \\\n",
       "count  469281.000000  4.692810e+05  469281.000000  469281.000000   \n",
       "mean       27.578334  2.299850e+05       0.044155       0.563647   \n",
       "std        18.366320  1.270919e+05       0.205439       0.166195   \n",
       "min         0.000000  3.344000e+03       0.000000       0.000000   \n",
       "25%        13.000000  1.750530e+05       0.000000       0.453000   \n",
       "50%        27.000000  2.149070e+05       0.000000       0.577000   \n",
       "75%        41.000000  2.638000e+05       0.000000       0.686000   \n",
       "max        98.000000  5.621218e+06       1.000000       0.991000   \n",
       "\n",
       "              energy            key       loudness           mode  \\\n",
       "count  469281.000000  469281.000000  469281.000000  469281.000000   \n",
       "mean        0.542439       5.224840     -10.200712       0.659208   \n",
       "std         0.251780       3.517928       5.086349       0.473976   \n",
       "min         0.000000       0.000000     -60.000000       0.000000   \n",
       "25%         0.344000       2.000000     -12.887000       0.000000   \n",
       "50%         0.550000       5.000000      -9.233000       1.000000   \n",
       "75%         0.749000       8.000000      -6.482000       1.000000   \n",
       "max         1.000000      11.000000       5.376000       1.000000   \n",
       "\n",
       "         speechiness   acousticness  instrumentalness       liveness  \\\n",
       "count  469281.000000  469281.000000     469281.000000  469281.000000   \n",
       "mean        0.104881       0.449396          0.113413       0.213992   \n",
       "std         0.179904       0.348656          0.266952       0.184386   \n",
       "min         0.000000       0.000000          0.000000       0.000000   \n",
       "25%         0.034000       0.096900          0.000000       0.098300   \n",
       "50%         0.044300       0.422000          0.000024       0.139000   \n",
       "75%         0.076400       0.784000          0.009460       0.278000   \n",
       "max         0.971000       0.996000          1.000000       1.000000   \n",
       "\n",
       "             valence          tempo  time_signature    num_artists  \\\n",
       "count  469281.000000  469281.000000   469281.000000  469281.000000   \n",
       "mean        0.552442     118.465459        3.873500       1.295914   \n",
       "std         0.257641      29.784032        0.472858       0.887235   \n",
       "min         0.000000       0.000000        0.000000       1.000000   \n",
       "25%         0.346000      95.549000        4.000000       1.000000   \n",
       "50%         0.564000     117.363000        4.000000       1.000000   \n",
       "75%         0.769000     136.335000        4.000000       1.000000   \n",
       "max         1.000000     243.507000        5.000000      58.000000   \n",
       "\n",
       "                year  \n",
       "count  469281.000000  \n",
       "mean     1988.594946  \n",
       "std        22.813764  \n",
       "min      1922.000000  \n",
       "25%      1974.000000  \n",
       "50%      1992.000000  \n",
       "75%      2007.000000  \n",
       "max      2021.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/tracks_cleaned.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Key is already an estimated value instead of actual we will drop it from the frame. Additonally, we drop release_date due to the inconsisitencies in the data where release_months are only available for some of the data. Since we have already created a column called year in the data cleaning part, we are still able to use that and take advantage of the strong relation between year and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['key', 'release_date'],axis=1, inplace=True)\n",
    "\n",
    "time_signature_df=pd.get_dummies(df[\"time_signature\"])\n",
    "df = pd.concat([df,time_signature_df],axis=1)\n",
    "df['mode'] = np.where(df['mode']=='Major', 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Modeling the data + Sets Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"] # all the features except popularity\n",
    "y = df[\"popularity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 469281 entries, 0 to 469280\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   duration_ms       469281 non-null  int64  \n",
      " 1   explicit          469281 non-null  int64  \n",
      " 2   danceability      469281 non-null  float64\n",
      " 3   energy            469281 non-null  float64\n",
      " 4   loudness          469281 non-null  float64\n",
      " 5   mode              469281 non-null  int64  \n",
      " 6   speechiness       469281 non-null  float64\n",
      " 7   acousticness      469281 non-null  float64\n",
      " 8   instrumentalness  469281 non-null  float64\n",
      " 9   liveness          469281 non-null  float64\n",
      " 10  valence           469281 non-null  float64\n",
      " 11  tempo             469281 non-null  float64\n",
      " 12  time_signature    469281 non-null  int64  \n",
      " 13  num_artists       469281 non-null  int64  \n",
      " 14  year              469281 non-null  int64  \n",
      " 15  0                 469281 non-null  uint8  \n",
      " 16  1                 469281 non-null  uint8  \n",
      " 17  3                 469281 non-null  uint8  \n",
      " 18  4                 469281 non-null  uint8  \n",
      " 19  5                 469281 non-null  uint8  \n",
      "dtypes: float64(9), int64(6), uint8(5)\n",
      "memory usage: 55.9 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_regression' (LinearRegression)\n",
      "Stored 'model_regression' (LinearRegression)\n",
      "Stored 'model_regression' (LinearRegression)\n",
      "Stored 'model_regression' (LinearRegression)\n",
      "Stored 'model_regression' (LinearRegression)\n",
      "Stored 'model_regression' (LinearRegression)\n",
      "Stored 'model_regression' (LinearRegression)\n",
      "Average Train Accuracy = 0.37647194405804696\n",
      "Average Test Accuracy = 0.3766325089388232\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(100):\n",
    "    # separate the data to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # save as np.array\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train) \n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #creating a regression model\n",
    "    model_regression = linear_model.LinearRegression()\n",
    "    model_regression.fit(X_train, y_train)\n",
    "\n",
    "   # to import to another jupyter notebook\n",
    "    %store model_regression\n",
    "\n",
    "    #We estimate models’ success rate in predicting the songs using the score() function which calculates the coefficient of determination. A score which is closer to 1 means the regressor is more accurate.\n",
    "    train = model_regression.score(X_train, y_train)\n",
    "    test = model_regression.score(X_test, y_test)\n",
    "\n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train = sum(train_scores) / len(train_scores)\n",
    "avg_test = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(\"Average Train Accuracy = \" + str(avg_train))\n",
    "print(\"Average Test Accuracy = \" + str(avg_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, when non-neglgible factors are accounted for, the success rate of a linear regression model in predicting popularity is 0.376 on average after 100 runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Non-essential factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/tracks_cleaned.csv')\n",
    "df.describe()\n",
    "\n",
    "df.drop(['key', 'release_date', 'num_artists', 'mode', 'speechiness', 'liveness', 'valence', 'tempo', 'time_signature'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"] # all the features except popularity\n",
    "y = df[\"popularity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Accuracy = 0.3746576507012922\n",
      "Average Test Accuracy = 0.3742977454816405\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(100):\n",
    "    # separate the data to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # save as np.array\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train) \n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #creating a regression model\n",
    "    model_regression = linear_model.LinearRegression()\n",
    "    model_regression.fit(X_train, y_train)\n",
    "\n",
    "    #We estimate models’ success rate in predicting the songs using the score() function which calculates the coefficient of determination. A score which is closer to 1 means the regressor is more accurate.\n",
    "    train = model_regression.score(X_train, y_train)\n",
    "    test = model_regression.score(X_test, y_test)\n",
    "\n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train = sum(train_scores) / len(train_scores)\n",
    "avg_test = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(\"Average Train Accuracy = \" + str(avg_train))\n",
    "print(\"Average Test Accuracy = \" + str(avg_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, dropping the non-essential features reduces the accuracy by around 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using top 6 features from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/tracks_cleaned.csv')\n",
    "df.describe()\n",
    "\n",
    "df.drop(['key', 'release_date', 'num_artists', 'mode', 'speechiness', 'liveness', 'valence', 'tempo', 'time_signature', 'instrumentalness'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.loc[:,df.columns !=\"popularity\"] # all the features except popularity\n",
    "y = df[\"popularity\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Accuracy = 0.36808090981203906\n",
      "Average Test Accuracy = 0.36785937199337787\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(100):\n",
    "    # separate the data to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # save as np.array\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train) \n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #creating a regression model\n",
    "    model_regression = linear_model.LinearRegression()\n",
    "    model_regression.fit(X_train, y_train)\n",
    "\n",
    "    #We estimate models’ success rate in predicting the songs using the score() function which calculates the coefficient of determination. A score which is closer to 1 means the regressor is more accurate.\n",
    "    train = model_regression.score(X_train, y_train)\n",
    "    test = model_regression.score(X_test, y_test)\n",
    "\n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train = sum(train_scores) / len(train_scores)\n",
    "avg_test = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(\"Average Train Accuracy = \" + str(avg_train))\n",
    "print(\"Average Test Accuracy = \" + str(avg_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the number of features further to important features reduces the success score of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, when it comes to regression models, using all the features gives a higher success rate than using only the essential ones. There could be several reasons for this:\n",
    "\n",
    "1. Even though some factors may have a weaker correlation with popularity, they may still provide some predictive power when used in combination with other factors. The model may be able to extract information from these weaker factors and use it to make more accurate predictions.\n",
    "\n",
    "2. It's possible that the non-negligible factors alone may not capture all the important information about popularity. There may be other factors that have a weaker correlation individually but when combined with other factors, they provide more useful information about popularity.\n",
    "\n",
    "Using all factors in a linear regression model could result in a higher success score because the weaker factors may still provide some predictive power, other factors could provide additional useful information, and including more factors could help to reduce multicollinearity issues.\n",
    "\n",
    "\n",
    "\n",
    "Nonetheless a success score of 0.3-0.4 is a weak score. As such, linear regression models may not be the best in predicting popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
